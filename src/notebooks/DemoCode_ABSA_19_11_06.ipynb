{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoCode-ABSA-19-11-06.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1o8MCPAHNiM",
        "colab_type": "text"
      },
      "source": [
        "Demo for aspect-based Sentiment Analysis shown at the jambit Meetup on 6th November 2019.\n",
        "\n",
        "Based mainly on [Ben Trevett's PyTorch Sentiment Analysis](https://github.com/bentrevett/pytorch-sentiment-analysis). The training and testing data is a prepared csv version of the restaurant data from the SemEval 2014 task on Aspect-based Sentiment Analysis.\n",
        "\n",
        "(c) Wiltrud Kessler\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYFUuo5iXJ4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv1QyddA4lf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import pytorch and torchtext libraries\n",
        "from torchtext import data\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYiJ5WWU42R7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task settings\n",
        "\n",
        "# The data we use has sentiment polarity annotations and aspect annotations.\n",
        "# There are 4 possible sentiment labels, '1', '-1', '0', and 'conflict'.\n",
        "# There are two types of aspect annotations in the data, 'category' (5 different aspect categories) and 'terms' (actual aspect words).\n",
        "# Chose here which setting to run: \n",
        "# Demo 1: Polarity classification -> labeltype 'category', use_aspect_label False. Play around with polarities, if you like.\n",
        "# Demo 2: Aspect category classification -> labeltype 'category', use_aspect_label True.\n",
        "# Demo 3: Aspect term classification -> labeltype 'term', use_aspect_label True.\n",
        "labeltype = 'category'\n",
        "polarities = ['1', '-1', '0', 'conflict']\n",
        "use_aspect_label = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZuAdyG8Wpl8",
        "colab_type": "code",
        "outputId": "5cec916d-4e94-4fa0-96b5-7d5f3add0b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "# Load the data from csv\n",
        "\n",
        "ID = data.Field()\n",
        "TEXT = data.Field()\n",
        "ASPECT = data.Field()\n",
        "POLARITY = data.Field()\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "# Select the columns of the csv file that we want to use\n",
        "# field ->   sent.id          text         ex.id          aspect           polarity\n",
        "if use_aspect_label:\n",
        "  fields = [(None, None), ('text', TEXT), (None, None), ('label', LABEL), (None, None)] # Use aspect as label\n",
        "else:\n",
        "  fields = [(None, None), ('text', TEXT), (None, None), (None, None), ('label', LABEL)] # Use polarity as label\n",
        "\n",
        "# The data is already split into training/validation/test to load with the corresponding names\n",
        "prefix = 'semeval2014_restaurants_' + labeltype + \"_\" + \".\".join(polarities)\n",
        "print(f'Loading data from {prefix}')\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "                                        path = '/content/drive/My Drive/semeval',\n",
        "                                        train = prefix + '_train.csv',\n",
        "                                        validation = prefix + '_val.csv',\n",
        "                                        test = prefix + '_test.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields,\n",
        "                                        skip_header = True\n",
        ")\n",
        "\n",
        "# Check if we loaded the right data by the number of examples\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')\n",
        "\n",
        "# Print some examples\n",
        "print(vars(train_data.examples[1]))\n",
        "print(vars(valid_data.examples[0]))\n",
        "print(vars(test_data.examples[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data from semeval2014_restaurants_category_1.-1.0.conflict\n",
            "Number of training examples: 2971\n",
            "Number of validation examples: 742\n",
            "Number of testing examples: 114\n",
            "{'text': ['the', 'food', 'itself', 'was', 'just', 'ok', 'nothing', 'spectacular', 'but', 'the', 'service', 'was', 'awful'], 'label': 'service'}\n",
            "{'text': ['i', 'love', 'the', 'fact', 'that', 'the', 'pizza', 'tastes', 'so', 'good', 'and', 'is', 'so', 'cheap'], 'label': 'food'}\n",
            "{'text': ['all', 'the', 'appetizers', 'and', 'salads', 'were', 'fabulous', 'the', 'steak', 'was', 'mouth', 'watering', 'and', 'the', 'pasta', 'was', 'delicious'], 'label': 'food'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lVIUH4A5Pht",
        "colab_type": "code",
        "outputId": "32b45f94-df21-44a4-a0ff-3839e7f475de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Build the vocabulary\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "MAX_LABEL_SIZE = 25_000 # take all\n",
        "\n",
        "# You can play around and throw out labels that are very rare in the dat\n",
        "#MAX_LABEL_SIZE = 60 # include aspect words that occur over 10 times (roughly)\n",
        "#MAX_LABEL_SIZE = 30 # include aspect words that occur over 20 times (roughly)\n",
        "#MAX_LABEL_SIZE = 10 # include aspect words that occur over 50 times (roughly)\n",
        "\n",
        "# Build the vocabulary only over the training data (test data is unknown)\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data, max_size = MAX_LABEL_SIZE)\n",
        "\n",
        "# Look at the numbers a bit\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Most frequent vocabulary words: {TEXT.vocab.freqs.most_common(20)}\")\n",
        "\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "print(f\"Classes distribution: {LABEL.vocab.freqs}\")\n",
        "\n",
        "if use_aspect_label:\n",
        "  print(f\"Most frequent class words: {LABEL.vocab.freqs.most_common(MAX_LABEL_SIZE)}\")\n",
        "  num = sum([x[1] for x in LABEL.vocab.freqs.most_common(MAX_LABEL_SIZE)])\n",
        "  if MAX_LABEL_SIZE < len(LABEL.vocab):\n",
        "    print(f\"Words with real label: {num} Words with default label {len(train_data)-num}\")\n",
        "\n",
        "# Move computations to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# The networks needs to be able to iterate over the data later on,\n",
        "# these iterators are defined here\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=False,\n",
        "    device = device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 4025\n",
            "Most frequent vocabulary words: [('the', 2722), ('and', 1699), ('a', 1089), ('is', 931), ('to', 874), ('i', 873), ('was', 649), ('food', 619), ('of', 614), ('for', 593), ('it', 552), ('in', 519), ('you', 433), ('but', 383), ('we', 378), ('this', 361), ('service', 359), ('with', 348), ('great', 320), ('that', 305)]\n",
            "Unique tokens in LABEL vocabulary: 5\n",
            "Classes distribution: Counter({'food': 989, 'anecdotes miscellaneous': 890, 'service': 475, 'ambience': 362, 'price': 255})\n",
            "Most frequent class words: [('food', 989), ('anecdotes miscellaneous', 890), ('service', 475), ('ambience', 362), ('price', 255)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZjiVT9B5mEX",
        "colab_type": "code",
        "outputId": "1e455eaf-1bca-4922-a3c8-448a8df0cb43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define the machine learning algorithm (Recurrent Neural Network)\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab) # each word is an input dimension\n",
        "EMBEDDING_DIM = 100 # this number falls from the sky and may be tuned ;)\n",
        "HIDDEN_DIM = 256 # this number falls from the sky and may be tuned ;)\n",
        "OUTPUT_DIM = len(LABEL.vocab) # each label is an output dimension\n",
        "\n",
        "# The network itself\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        return self.fc(hidden.squeeze(0))\n",
        "\n",
        "# Just for debugging\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Get an instance of our model\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "# Set other parameters for the network (optimizer, loss function)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device) # move to GPU, if we have one\n",
        "criterion = criterion.to(device) # move to GPU, if we have one\n",
        "\n",
        "# Define the metric for evaluation = accuracy\n",
        "def categorical_accuracy(preds, y):\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y) # check if it is correct\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])\n",
        "\n",
        "# Define the actual training\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.text)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "# Define the actual evaluation\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():    \n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 495,433 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J9kR0Yi55gJ",
        "colab_type": "code",
        "outputId": "90bff59e-cc02-412c-ca04-5ee622529beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "# Actually train the model\n",
        "\n",
        "N_EPOCHS = 10 # Set to a higher value\n",
        "\n",
        "# Debug function to show how much time one iteration takes\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# Train the model a few times on the training data and evaluate it\n",
        "# on the validation data. Save the best model.\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'absa1.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.549 | Train Acc: 29.38%\n",
            "\t Val. Loss: 1.562 |  Val. Acc: 28.67%\n",
            "Epoch: 02 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.503 | Train Acc: 32.88%\n",
            "\t Val. Loss: 1.541 |  Val. Acc: 29.32%\n",
            "Epoch: 03 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.490 | Train Acc: 33.15%\n",
            "\t Val. Loss: 1.532 |  Val. Acc: 29.45%\n",
            "Epoch: 04 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.492 | Train Acc: 33.06%\n",
            "\t Val. Loss: 1.529 |  Val. Acc: 29.71%\n",
            "Epoch: 05 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.490 | Train Acc: 33.01%\n",
            "\t Val. Loss: 1.527 |  Val. Acc: 28.80%\n",
            "Epoch: 06 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.487 | Train Acc: 33.16%\n",
            "\t Val. Loss: 1.526 |  Val. Acc: 29.06%\n",
            "Epoch: 07 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.490 | Train Acc: 33.02%\n",
            "\t Val. Loss: 1.525 |  Val. Acc: 29.19%\n",
            "Epoch: 08 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.489 | Train Acc: 32.95%\n",
            "\t Val. Loss: 1.525 |  Val. Acc: 28.67%\n",
            "Epoch: 09 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.488 | Train Acc: 33.16%\n",
            "\t Val. Loss: 1.524 |  Val. Acc: 29.06%\n",
            "Epoch: 10 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.489 | Train Acc: 33.03%\n",
            "\t Val. Loss: 1.525 |  Val. Acc: 29.06%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0oA6VWu59ir",
        "colab_type": "code",
        "outputId": "33079acb-ab61-4c2c-de5a-0e06a4af5a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluate the model on the test data\n",
        "\n",
        "model.load_state_dict(torch.load('absa1.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Accuracy: {test_acc*100:.2f}%')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 36.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZyBm8_Q6ANT",
        "colab_type": "code",
        "outputId": "5391bfaa-8797-449d-d318-af23ca959e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# Try out a few examples by hand\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "def custom_tokenize(text):\n",
        "    tokenizer = WordPunctTokenizer()\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    words = [word for word in tokens if word.isalnum()]\n",
        "    return words\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval() # Put model in eval mode\n",
        "    tokenized = custom_tokenize(sentence)\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    predictions = torch.sigmoid(model(tensor))\n",
        "    max_prediction = predictions.argmax(dim = 1)\n",
        "    return predictions.tolist(), max_prediction.item()\n",
        "\n",
        "# POLARITY examples\n",
        "if not use_aspect_label:\n",
        "  # Label here is human-readable, i.e. 0 is neutral, 1 is positive, -1 is negative\n",
        "  sentences = [\n",
        "      (\"The food was delicious.\", \"1\"),\n",
        "      (\"This is by far my favorite place in the neighborhood\", \"1\"),\n",
        "      (\"The sushi was awful!\", \"-1\"),\n",
        "      (\"Service was prompt, friendly and great.\", \"1\"),\n",
        "      (\"The website and rating makes this place look wonderful but in reality it was very disappointing.\", \"conflict\"),\n",
        "      (\"I know because I live nearby.\", \"0\")\n",
        "  ]\n",
        "\n",
        "# ASPECT CATEGORY examples\n",
        "if labeltype == 'category' and use_aspect_label:\n",
        "   sentences = [\n",
        "      (\"The food was delicious.\", \"food\"),\n",
        "      (\"This is by far my favorite place in the neighborhood\", \"anecdotes/miscellaneous\"),\n",
        "      (\"The sushi was awful!\", \"food\"),\n",
        "      (\"Service was prompt, friendly and great.\", \"service\"),\n",
        "      (\"in the neighborhood it is well worth the price you pay for them.\", \"price\")\n",
        "   ]\n",
        "\n",
        "# ASPECT TERM examples\n",
        "if labeltype == 'term' and use_aspect_label:\n",
        "   sentences = [\n",
        "      (\"The food was delicious.\", \"food\"),\n",
        "      (\"The sushi was awful!\", \"sushi\"),\n",
        "      (\"My pick for best pizza restaurant anywhere!\", \"pizza\"),\n",
        "      (\"The atmosphere isn't the greatest , but I suppose that's how they keep the prices down .\", \"atmosphere\"),\n",
        "      (\"The atmosphere isn't the greatest , but I suppose that's how they keep the prices down .\", \"prices\"),\n",
        "      (\"the desert was good.\", \"desert\")\n",
        "   ]\n",
        "\n",
        "for s in sentences:\n",
        "   result = predict_sentiment(model, s[0])\n",
        "   predicted_label = LABEL.vocab.itos[result[1]]\n",
        "   print(f'Sentence: {s[0]}\\n   {str(s[1]) == predicted_label}! - Gold label: {s[1]} Predicted label: {predicted_label} Probabilities: {result[0]}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: The food was delicious.\n",
            "   False! - Gold label: food Predicted label: anecdotes miscellaneous Probabilities: [[0.4999088943004608, 0.6480996012687683, 0.5152636170387268, 0.47140341997146606, 0.5139840841293335]]\n",
            "Sentence: This is by far my favorite place in the neighborhood\n",
            "   False! - Gold label: anecdotes/miscellaneous Predicted label: price Probabilities: [[0.40385672450065613, 0.5065933465957642, 0.5013625621795654, 0.35134658217430115, 0.5374458432197571]]\n",
            "Sentence: The sushi was awful!\n",
            "   False! - Gold label: food Predicted label: service Probabilities: [[0.4620286524295807, 0.5587091445922852, 0.5747478604316711, 0.5376664400100708, 0.465562641620636]]\n",
            "Sentence: Service was prompt, friendly and great.\n",
            "   False! - Gold label: service Predicted label: ambience Probabilities: [[0.4959174394607544, 0.5272541046142578, 0.4452691078186035, 0.5982636213302612, 0.575789749622345]]\n",
            "Sentence: in the neighborhood it is well worth the price you pay for them.\n",
            "   True! - Gold label: price Predicted label: price Probabilities: [[0.5071384310722351, 0.5364519953727722, 0.5166339874267578, 0.5122401714324951, 0.619090735912323]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}